{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from numpy import zeros, log, array\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import scipy.spatial.distance as dist\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.path.expanduser(\"~/Google Drive/CSVs/artname-plays.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MusicData(object):\n",
    "    def __init__(self, filename):\n",
    "        # load TSV file from disk\n",
    "        self.data = pd.read_table(filename,\n",
    "                                      usecols=[0, 2, 3],\n",
    "                                      names=['user', 'artist', 'plays'])\n",
    "\n",
    "        # generate sets for artists/users\n",
    "        self.artist_sets = dict((artist, set(users)) for artist, users in\n",
    "                                self.data.groupby('artist')['user'])\n",
    "        self.user_sets = dict((user, set(artists)) for user, artists in\n",
    "                              self.data.groupby('user')['artist'])\n",
    "\n",
    "        # assign each user a unique numeric id\n",
    "        userids = defaultdict(lambda: len(userids))\n",
    "        self.data['userid'] = self.data['user'].map(userids.__getitem__)\n",
    "\n",
    "        # get a sparse vector for each artist\n",
    "        self.artists = dict((artist,\n",
    "                             csr_matrix((array(group['plays']),\n",
    "                                         (zeros(len(group)),\n",
    "                                         group['userid'])),\n",
    "                                        shape=[1, len(userids)]))\n",
    "                            for artist, group in self.data.groupby('artist'))\n",
    "\n",
    "        N = len(self.artists)\n",
    "        self.idf = [1. + log(N / (1. + p)) for p in self.data.groupby('userid').size()]\n",
    "        self.average_plays = self.data['plays'].sum() / float(N)\n",
    "\n",
    "\n",
    "def clean_dataset(filename):\n",
    "    \"\"\" so - i lied a little in the post about it being a one line operation\n",
    "    to read in the dataset with pandas.\n",
    "    it *should* be a one line operation, but there are a bunch of malformed\n",
    "    lines in the dataset that trips up pandas. So lets read in the thing one\n",
    "    line at a time, and strip out the bad data. After this runs it will be a\n",
    "    one-liner to read in. honest this time \"\"\"\n",
    "\n",
    "    with open(filename + \".cleaned\", \"w\") as output:\n",
    "        for i, line in enumerate(open(filename)):\n",
    "            tokens = line.strip().split(\"\\t\")\n",
    "            if len(tokens) != 4:\n",
    "                print(\"wrong # of tokens\", i)\n",
    "                continue\n",
    "\n",
    "            if not tokens[3].isdigit():\n",
    "                print(\"non integer play count\", i)\n",
    "                continue\n",
    "\n",
    "            if tokens[2] == '\"\"':\n",
    "                print(\"invalid artist id\", tokens[2])\n",
    "                continue\n",
    "\n",
    "            # some lines contain carriage returns (without newlines), which\n",
    "            # randomly messes pandas up\n",
    "            line = line.replace('\\r', '')\n",
    "\n",
    "            output.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mdata = MusicData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\" Reads in the last.fm dataset, and returns a tuple of a pandas dataframe\n",
    "    and a sparse matrix of artist/user/playcount \"\"\"\n",
    "    # read in triples of user/artist/playcount from the input dataset\n",
    "    data = pd.read_table(filename,\n",
    "                             usecols=[0, 2, 3],\n",
    "                             names=['user', 'artist', 'plays'])\n",
    "\n",
    "    # map each artist and user to a unique numeric value\n",
    "    data['user'] = data['user'].astype(\"category\")\n",
    "    data['artist'] = data['artist'].astype(\"category\")\n",
    "\n",
    "    # create a sparse matrix of all the users/plays\n",
    "    plays = coo_matrix((data['plays'].astype(float),\n",
    "                       (data['artist'].cat.codes.copy(),\n",
    "                        data['user'].cat.codes.copy())))\n",
    "\n",
    "    return data, plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlap(a, b):\n",
    "    return len(a.intersection(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#musicD = MusicData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine1(plays):\n",
    "    normalized = normalize(plays)\n",
    "    return normalized.dot(normalized.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bhattacharya(plays):\n",
    "    plays.data = np.sqrt(plays.data)\n",
    "    return cosine(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ochiai(plays):\n",
    "    plays = csr_matrix(plays)\n",
    "    plays.data = np.ones(len(plays.data))\n",
    "    return cosine(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm25_weight(data, K1=100, B=0.8):\n",
    "    \"\"\" Weighs each row of the matrix data by BM25 weighting \"\"\"\n",
    "    # calculate idf per term (user)\n",
    "    N = float(data.shape[0])\n",
    "    idf = np.log(N / (1 + np.bincount(data.col)))\n",
    "\n",
    "    # calculate length_norm per document (artist)\n",
    "    row_sums = np.squeeze(np.asarray(data.sum(1)))\n",
    "    average_length = row_sums.sum() / N\n",
    "    length_norm = (1.0 - B) + B * row_sums / average_length\n",
    "\n",
    "    # weight matrix rows by bm25\n",
    "    ret = coo_matrix(data)\n",
    "    ret.data = ret.data * (K1 + 1.0) / (K1 * length_norm[ret.row] + ret.data) * idf[ret.col]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm25(plays):\n",
    "    plays = bm25_weight(plays)\n",
    "    return plays.dot(plays.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.expanduser(\"~/Google Drive/CSVs/artname-plays.tsv.cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, plays = read_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_largest(row, N=10):\n",
    "    if N >= row.nnz:\n",
    "        best = zip(row.data, row.indices)\n",
    "    else:\n",
    "        ind = np.argpartition(row.data, -N)[-N:]\n",
    "        best = zip(row.data[ind], row.indices[ind])\n",
    "    return sorted(best, reverse=True)\n",
    "\n",
    "\n",
    "def calculate_similar_artists(similarity, artists, artistid):\n",
    "    neighbours = similarity[artistid]\n",
    "    top = get_largest(neighbours)\n",
    "    return [(artists[other], score, i) for i, (score, other) in enumerate(top)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity = cosine(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#similarity = bm25(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#similarity = cosine2(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artists = dict(enumerate(data['artist'].cat.categories))\n",
    "user_count = data.groupby('artist').size()\n",
    "to_generate = sorted(list(artists), key=lambda x: -user_count[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for artist in to_generate:\n",
    "    name = artists[artist]\n",
    "    for other, score, rank in calculate_similar_artists(similarity, artists, artist):\n",
    "            l.append([name, other, score, rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = pd.DataFrame(l, columns=['name', 'other', 'score', 'rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0a66d4489ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sim' is not defined"
     ]
    }
   ],
   "source": [
    "sim.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numberList = [1, 2, 3]\n",
    "strList = ['one', 'two', 'three']\n",
    "\n",
    "# Two iterables are passed\n",
    "result = zip(numberList, strList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'one')\n",
      "(2, 'two')\n",
      "(3, 'three')\n"
     ]
    }
   ],
   "source": [
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en = enumerate(numberList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1), (1, 2), (2, 3)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
